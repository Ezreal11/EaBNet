{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5e30cba4-956d-4525-bec5-3aab20e9038e",
   "metadata": {},
   "source": [
    "# Load model and ckp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bf533a2-22c8-44b5-b957-0e96d4d94daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pickle\n",
    "from EaBNet import make_eabnet_with_postnet\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3ec6f5d-b3b4-479d-85c2-6437640af72a",
   "metadata": {},
   "outputs": [],
   "source": [
    "args_path = 'data/experiments/eabnet/train_bs8/args.pickle'\n",
    "with open(args_path, 'rb') as file:\n",
    "    args = pickle.load(file)\n",
    "\n",
    "ckp_path = 'data/experiments/eabnet/train_2nd_stage_with_postnet/checkpoints/351864.pth'\n",
    "model_ckp = torch.load(ckp_path, map_location='cpu')['model_state_dict']\n",
    "model = make_eabnet_with_postnet(args)\n",
    "model.load_state_dict(model_ckp, strict=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cda2869b-7996-41e1-8e17-05b3e188e1b8",
   "metadata": {},
   "source": [
    "# Make a dataset sample "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d79bb1a-7cdd-4ebc-b60f-03ed8171ed1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset.mcse_dataset import generate_random_noisy_for_speech, load_audio_and_random_crop\n",
    "import json\n",
    "import os\n",
    "from scipy.io import wavfile\n",
    "import scipy.signal as signal\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c55548b-3c5e-49c5-99c5-890a8a569014",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all noises\n",
    "noise_root = 'data/datasets/datasets_fullband/noise_fullband'\n",
    "noise_records = os.listdir(noise_root)\n",
    "noise_records.sort()\n",
    "print(len(noise_records))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e086aba4-e85c-4fe6-95af-176d5b983ed8",
   "metadata": {},
   "source": [
    "## resample to 16khz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebac30ab-17db-41e2-9279-8fd7d81fc623",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_name = '00032'\n",
    "audio_dir = './demo'\n",
    "audio_path = os.path.join(audio_dir, audio_name+'.wav')\n",
    "fs, audio = wavfile.read(audio_path)\n",
    "print(fs,audio.shape)\n",
    "assert len(audio.shape)==1\n",
    "\n",
    "resample_fs = 16000\n",
    "if fs!=resample_fs:\n",
    "    audio = signal.resample(audio, int(resample_fs*len(audio)/fs)).astype(audio.dtype)\n",
    "    wavfile.write(audio_path, resample_fs, audio)\n",
    "    fs, audio = wavfile.read(audio_path)\n",
    "    print(fs,audio.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbac3b89-b61a-40cc-8a0d-dc2faf348ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def generate_random_noisy_for_speech(opt, clip_seconds, target_speech, all_noises, speech_root, noise_root, speech_start_sec=None):\n",
    "with open('dataset/mcse_dataset_settings.json','r') as f:\n",
    "    opt = json.load(f)\n",
    "\n",
    "target_speech = audio_name + '.wav'\n",
    "speech_root = audio_dir\n",
    "noise_root = 'demo/noise'\n",
    "all_noises = os.listdir(noise_root)\n",
    "clip_seconds = 2\n",
    "\n",
    "specific = {\n",
    "    'noisy_dBFS': -30,\n",
    "    'noise_snr_list': [-1.5,-1.5]\n",
    "}\n",
    "\n",
    "sample = generate_random_noisy_for_speech(opt, clip_seconds, target_speech, all_noises, speech_root, noise_root, speech_start_sec=0, \n",
    "                                         specific=specific)\n",
    "meta = sample['meta']\n",
    "room = sample['room']\n",
    "freefield = sample['freefield']\n",
    "noisy = sample['noisy']\n",
    "clean = sample['clean']\n",
    "fig, ax = room.plot(img_order=0)\n",
    "print(ax)\n",
    "ax.view_init(elev=90,azim=-90)\n",
    "ax.set_xlabel('x')\n",
    "ax.set_ylabel('y')\n",
    "print(meta)\n",
    "plt.show()\n",
    "\n",
    "def show_audio(audio,fs,name):\n",
    "    print(f'{name} shape={audio.shape}')\n",
    "    plt.plot(audio)\n",
    "    plt.show()\n",
    "    IPython.display.display(IPython.display.Audio(audio, rate=fs))\n",
    "    \n",
    "# plt.plot(room.rir[0][0])\n",
    "# plt.show()\n",
    "# plt.plot(freefield.rir[0][0])\n",
    "# plt.show()\n",
    "print(noisy.shape)\n",
    "print(clean.shape)\n",
    "show_audio(noisy[0],fs,'noisy[0]')\n",
    "show_audio(clean,fs,'clean')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8f9dd8-85c5-44e1-9cb8-3e30ebc4a27c",
   "metadata": {},
   "source": [
    "# Model inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc89c872-a836-44cb-9c83-ec11dc7059cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_distributed import prepare_data\n",
    "\n",
    "model = model.cuda()\n",
    "\n",
    "def to_tensor(x):\n",
    "    return torch.tensor(x,dtype=torch.float)[None]\n",
    "noisy_stft, target_stft = prepare_data(to_tensor(noisy), to_tensor(clean), 'cuda', args)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(noisy_stft)\n",
    "    \n",
    "device = 'cuda'\n",
    "esti_stft=output['esti_stft']\n",
    "print(esti_stft.shape)\n",
    "sr = args.sr\n",
    "wav_len = int(args.wav_len * sr)\n",
    "win_size = int(args.win_size * sr)\n",
    "win_shift = int(args.win_shift * sr)\n",
    "fft_num = args.fft_num\n",
    "esti_stft = esti_stft.permute(0, 3, 2, 1)\n",
    "print(esti_stft.shape)\n",
    "esti_wav = torch.istft(torch.view_as_complex(esti_stft.contiguous()), fft_num, win_shift, win_size, torch.hann_window(win_size).to(device))\n",
    "esti_wav = esti_wav.cpu().numpy()   #[1, 76640]\n",
    "\n",
    "show_audio(esti_wav[0], 16000,'esti_wav')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
